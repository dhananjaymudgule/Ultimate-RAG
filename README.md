# Ultimate-RAG

## ğŸ“Œ Overview
Ultimate-RAG is a **Retrieval-Augmented Generation (RAG) system** that enables intelligent document processing and query answering using **LLMs (Large Language Models)**. It allows users to **upload documents, embed them using Googleâ€™s text embedding model, store embeddings in a vector database (Pinecone), retrieve relevant documents, and generate responses** dynamically using different LLMs.

## ğŸš€ Features
- ğŸ“‚ **File Uploading**: Supports various file types (JSON, PDF, CSV, etc.).
- ğŸ— **Document Embedding**: Converts document content into vector embeddings for efficient retrieval.
- ğŸ” **Document Retrieval**: Uses vector search (Pinecone, FAISS, Chroma) to find relevant content.
- ğŸ§  **AI-Powered Answers**: Uses LLMs like **Gemini, OpenAI, etc.** to generate responses.
- âœ… **Modular & Scalable**: Supports multiple embedding models and vector stores dynamically.
- ğŸŒ **Web UI**: Interactive frontend using **Streamlit**.

## ğŸ— Directory Structure
```
ULTIMATE-RAG/
â”‚â”€â”€ src/
â”‚   â”‚â”€â”€ app/
â”‚   â”‚   â”‚â”€â”€ api/               # âœ… API routes
â”‚   â”‚   â”‚   â”‚â”€â”€ routes/
â”‚   â”‚   â”‚   â”‚   â”‚â”€â”€ upload.py  # Handles file uploads
â”‚   â”‚   â”‚   â”‚   â”‚â”€â”€ query.py   # Handles LLM queries
â”‚   â”‚   â”‚   â”‚â”€â”€ dependencies.py  # Dependency injection (if needed)
â”‚   â”‚   â”‚â”€â”€ core/              # âœ… Core configurations
â”‚   â”‚   â”‚   â”‚â”€â”€ config.py      # App settings & environment variables
â”‚   â”‚   â”‚â”€â”€ services/          # âœ… Business logic
â”‚   â”‚   â”‚   â”‚â”€â”€ vector_store.py # Vector database management
â”‚   â”‚   â”‚   â”‚â”€â”€ retrieval_service.py # Retrieval logic from Pinecone
â”‚   â”‚   â”‚   â”‚â”€â”€ query_service.py  # Query processing logic
â”‚   â”‚   â”‚   â”‚â”€â”€ file_processors/  # âœ… Handles file-specific processing
â”‚   â”‚   â”‚   â”‚   â”‚â”€â”€ json_processor.py  # JSON processing logic
â”‚   â”‚   â”‚   â”‚   â”‚â”€â”€ pdf_processor.py   # (Future) PDF processing logic
â”‚   â”‚   â”‚   â”‚â”€â”€ file_handler.py  # âœ… Detects file types & calls processors
â”‚   â”‚   â”‚â”€â”€ prompts/            # âœ… Stores LLM prompts
â”‚   â”‚   â”‚   â”‚â”€â”€ prompt_templates.py # Defines system & human prompts
â”‚   â”‚   â”‚â”€â”€ utils/              # âœ… Utility functions (if needed)
â”‚   â”‚â”€â”€ uploads/                # âœ… Stores uploaded files
â”‚â”€â”€ streamlit_app/              # âœ… Frontend UI (Streamlit)
â”‚   â”‚â”€â”€ app.py                  # Streamlit interface
â”‚â”€â”€ ultimate/                   # Virtual environment
â”‚â”€â”€ .env                        # âœ… Environment variables
â”‚â”€â”€ requirements.txt            # Dependencies
â”‚â”€â”€ README.md                   # Project documentation
â”‚â”€â”€ LICENSE                     # License file
â”‚â”€â”€ .gitignore                  # Ignore unnecessary files
```

## ğŸ“¦ Installation & Setup
### **1ï¸âƒ£ Create Virtual Environment**
```bash
python -m venv ultimate
ultimate\Scripts\activate  # On Windows
source ultimate/bin/activate  # On Mac/Linux
```

### **2ï¸âƒ£ Install Dependencies**
```bash
python.exe -m pip install --upgrade pip
pip install -r requirements.txt
```

### **3ï¸âƒ£ Set Up Environment Variables**
Create a `.env` file in the project root:
```
PINECONE_API_KEY=your_pinecone_api_key
GEMINI_API_KEY=your_google_gemini_api_key
EMBEDDING_MODEL_NAME=models/text-embedding-004
```

## ğŸƒâ€â™‚ï¸ Running the Project
### **1ï¸âƒ£ Start FastAPI Backend**
```bash
uvicorn src.app.main:app --reload
```
- **Swagger UI (API Docs)** â†’ [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)
- **Redoc UI** â†’ [http://127.0.0.1:8000/redoc](http://127.0.0.1:8000/redoc)
- **Health Check** â†’ [http://127.0.0.1:8000/](http://127.0.0.1:8000/)

### **2ï¸âƒ£ Start Streamlit Frontend**
```bash
cd streamlit_app
streamlit run app.py
```

## ğŸ›  API Endpoints
### **1ï¸âƒ£ File Upload API** (`upload.py`)
| Method | Endpoint         | Description                  |
|--------|-----------------|------------------------------|
| `POST` | `/files/upload/` | Upload a single file         |
| `POST` | `/files/upload-multiple/` | Upload multiple files |

### **2ï¸âƒ£ Query API** (`query.py`)
| Method | Endpoint      | Description               |
|--------|--------------|---------------------------|
| `POST` | `/query/ask` | Ask a question to the LLM |

## ğŸ— Project Architecture
### **ğŸ”¹ 1ï¸âƒ£ API Layer (`api/routes/`)**
- **`upload.py`** â†’ Handles file uploads
- **`query.py`** â†’ Processes user queries via LLM

### **ğŸ”¹ 2ï¸âƒ£ Business Logic (`services/`)**
- **`query_service.py`** â†’ Manages query processing & LLM calls
- **`retrieval_service.py`** â†’ Fetches documents from vector DB
- **`vector_store.py`** â†’ Handles storage/retrieval of embeddings

### **ğŸ”¹ 3ï¸âƒ£ File Handling (`file_processors/`)**
- **`json_processor.py`** â†’ Parses JSON files & extracts data
- **`pdf_processor.py`** â†’ (Future) Extracts text from PDFs
- **`file_handler.py`** â†’ Detects file type & calls processor

### **ğŸ”¹ 4ï¸âƒ£ Prompt Management (`prompts/`)**
- **`prompt_templates.py`** â†’ Stores system & human prompts

### **ğŸ”¹ 5ï¸âƒ£ Utilities (`utils/`)**
- **`logger.py`** â†’ Logs system activity
- **`dependencies.py`** â†’ Handles dependency injection

## ğŸ¯ Future Enhancements
- âœ… Add support for **PDF, CSV, and DOCX file processing**
- âœ… Implement **multi-vector database support (Weaviate, Qdrant, Milvus)**
- âœ… Support **multiple LLMs dynamically (OpenAI, Gemini, Cohere, etc.)**
- âœ… Improve **retrieval with advanced ranking algorithms (BM25, Hybrid Search)**



